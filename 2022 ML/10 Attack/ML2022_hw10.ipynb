{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-n2e0BkhEKS"
   },
   "source": [
    "# **Homework 10 - Adversarial Attack**\n",
    "\n",
    "Slides: https://reurl.cc/7DDxnD\n",
    "\n",
    "Contact: ntu-ml-2022spring-ta@googlegroups.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RX7iRXrhMA_"
   },
   "source": [
    "## Enviroment & Download\n",
    "\n",
    "We make use of [pytorchcv](https://pypi.org/project/pytorchcv/) to obtain CIFAR-10 pretrained model, so we need to set up the enviroment first. We also need to download the data (200 images) which we want to attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4Lw7urignqP",
    "outputId": "338b4e04-9d1d-47c4-d8e5-81eb45705c5c"
   },
   "source": [
    "```bash\n",
    "# set up environment\n",
    "import sys\n",
    "!{sys.executable} -m pip install pytorchcv\n",
    "!{sys.executable} -m pip install imgaug\n",
    "\n",
    "# download\n",
    "!wget https://github.com/DanielLin94144/ML-attack-dataset/files/8167812/data.zip\n",
    "\n",
    "# unzip\n",
    "!unzip ./data.zip\n",
    "!rm ./data.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5inbFx_alYjw"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda is NOT available!!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(device) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda is NOT available!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda is NOT available!!"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if str(device) == 'cpu':\n",
    "    raise RuntimeError(\"cuda is NOT available!!\")\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkQQf0l1hbBs"
   },
   "source": [
    "## Global Settings \n",
    "#### **[NOTE]**: Don't change the settings here, or your generated image might not meet the constraint.\n",
    "* $\\epsilon$ is fixed to be 8. But on **Data section**, we will first apply transforms on raw pixel value (0-255 scale) **by ToTensor (to 0-1 scale)** and then **Normalize (subtract mean divide std)**. $\\epsilon$ should be set to $\\frac{8}{255 * std}$ during attack.\n",
    "\n",
    "* Explaination (optional)\n",
    "    * Denote the first pixel of original image as $p$, and the first pixel of adversarial image as $a$.\n",
    "    * The $\\epsilon$ constraints tell us $\\left| p-a \\right| <= 8$.\n",
    "    * ToTensor() can be seen as a function where $T(x) = x/255$.\n",
    "    * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
    "    * After applying ToTensor() and Normalize() on $p$ and $a$, the constraint becomes $\\left| N(T(p))-N(T(a)) \\right| = \\left| \\frac{\\frac{p}{255}-mean}{std}-\\frac{\\frac{a}{255}-mean}{std} \\right| = \\frac{1}{255 * std} \\left| p-a \\right| <= \\frac{8}{255 * std}.$\n",
    "    * So, we should set $\\epsilon$ to be $\\frac{8}{255 * std}$ after ToTensor() and Normalize()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACghc_tsg2vE"
   },
   "outputs": [],
   "source": [
    "# the mean and std are the calculated statistics from cifar_10 dataset\n",
    "cifar_10_mean = (0.491, 0.482, 0.447) # mean for the three channels of cifar_10 images\n",
    "cifar_10_std = (0.202, 0.199, 0.201) # std for the three channels of cifar_10 images\n",
    "\n",
    "# convert mean and std to 3-dimensional tensors for future operations\n",
    "mean = torch.tensor(cifar_10_mean).to(device).view(3, 1, 1)\n",
    "std = torch.tensor(cifar_10_std).to(device).view(3, 1, 1)\n",
    "\n",
    "epsilon = 8/255/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uO8f0NmtlM63"
   },
   "outputs": [],
   "source": [
    "root = './data' # directory for storing benign images\n",
    "# benign images: images which do not contain adversarial perturbations\n",
    "# adversarial images: images which include adversarial perturbations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhBJBAlKherZ"
   },
   "source": [
    "## Data\n",
    "\n",
    "Construct dataset and dataloader from root directory. Note that we store the filename of each image for future usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXpRAHz0hkDt",
    "outputId": "7821e9f3-aa8b-4eed-ce82-fbece547da74"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(cifar_10_mean, cifar_10_std)  # Normalize the image using predefined means and standard deviations\n",
    "])\n",
    "\n",
    "class AdvDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform):\n",
    "        self.images = []  # List to store image paths\n",
    "        self.labels = []  # List to store corresponding labels\n",
    "        self.names = []  # List to store the relative paths of images\n",
    "        \n",
    "        '''\n",
    "        data_dir\n",
    "        ├── class_dir\n",
    "        │   ├── class1.png\n",
    "        │   ├── ...\n",
    "        │   ├── class20.png\n",
    "        '''\n",
    "        \n",
    "        # Iterate over class directories in the given data directory\n",
    "        for i, class_dir in enumerate(sorted(glob.glob(f'{data_dir}/*'))):\n",
    "            images = sorted(glob.glob(f'{class_dir}/*'))  # Get a list of image paths in each class directory\n",
    "            self.images += images  # Append the image paths to the list\n",
    "            self.labels += ([i] * len(images))  # Assign labels to the images based on the class index\n",
    "            self.names += [os.path.relpath(imgs, data_dir) for imgs in images]  # Get the relative paths of the images\n",
    "        \n",
    "        self.transform = transform  # Transformation to be applied to each image\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.transform(Image.open(self.images[idx]))  # Load and transform the image at the given index\n",
    "        label = self.labels[idx]  # Get the corresponding label\n",
    "        return image, label  # Return the transformed image and its label\n",
    "    \n",
    "    def __getname__(self):\n",
    "        return self.names  # Return the list of image names\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)  # Return the total number of images in the dataset\n",
    "\n",
    "adv_set = AdvDataset(root, transform=transform)  # Create an instance of the AdvDataset\n",
    "adv_names = adv_set.__getname__()  # Get the list of image names from the dataset\n",
    "adv_loader = DataLoader(adv_set, batch_size=batch_size, shuffle=False)  # Create a data loader for the dataset\n",
    "\n",
    "print(f'number of images = {adv_set.__len__()}')  # Print the total number of images in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnszlTsYrTQZ"
   },
   "source": [
    "## Utils -- Benign Images Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5c_zZLzkrceE"
   },
   "outputs": [],
   "source": [
    "# to evaluate the performance of the model on benign images\n",
    "def epoch_benign(model, loader, loss_fn):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    train_acc, train_loss = 0.0, 0.0  # Initialize accuracy and loss variables\n",
    "\n",
    "    # Iterate over the data loader\n",
    "    for x, y in loader:  # x: image, y: label\n",
    "        x, y = x.to(device), y.to(device)  # Move the input data to the appropriate device (e.g., GPU)\n",
    "        yp = model(x)  # Forward pass through the model to get predictions\n",
    "        loss = loss_fn(yp, y)  # Compute the loss between predictions and ground truth labels\n",
    "        train_acc += (yp.argmax(dim=1) == y).sum().item()  # Count correct predictions and add them to the accuracy\n",
    "        train_loss += loss.item() * x.shape[0]  # Multiply the loss by batch size and add it to the total loss\n",
    "\n",
    "    # Calculate the average accuracy and loss per sample\n",
    "    return train_acc / len(loader.dataset), train_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YJxK7YehqQy"
   },
   "source": [
    "## Utils -- Attack Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_1wKfKyhrQW"
   },
   "outputs": [],
   "source": [
    "# perform fgsm attack\n",
    "def fgsm(model, x, y, loss_fn, epsilon=epsilon):\n",
    "    x_adv = x.detach().clone() # initialize x_adv as original benign image x, by creating a clone of the input tensor 'x' and detach it from the computation graph\n",
    "    x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
    "    loss = loss_fn(model(x_adv), y) # calculate loss\n",
    "    loss.backward() # calculate gradient\n",
    "    # fgsm: use gradient ascent on x_adv to maximize loss\n",
    "    grad = x_adv.grad.detach() # Compute gradients of the loss with respect to 'x_adv'\n",
    "    x_adv = x_adv + epsilon * grad.sign() # Create an adversarial example by adding a perturbation in the direction of the sign of the gradients\n",
    "    return x_adv\n",
    "\n",
    "# num_iter can be decided by yourself\n",
    "def ifgsm(model, x, y, loss_fn, epsilon:float=epsilon, num_iter:int=20):\n",
    "    if num_iter < 1:\n",
    "        raise RuntimeError(f\"num_iter, {num_iter}, needs to be greater than 0!\") \n",
    "    alpha = epsilon / num_iter\n",
    "    x_adv = x\n",
    "    # write a loop of num_iter to represent the iterative times\n",
    "    for i in range(num_iter):\n",
    "        # x_adv = fgsm(model, x_adv, y, loss_fn, alpha) # call fgsm with (epsilon = alpha) to obtain new x_adv\n",
    "        x_adv = x_adv.detach().clone()\n",
    "        x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
    "        loss = loss_fn(model(x_adv), y) # calculate loss\n",
    "        loss.backward() # calculate gradient\n",
    "        # fgsm: use gradient ascent on x_adv to maximize loss\n",
    "        grad = x_adv.grad.detach()\n",
    "        x_adv = x_adv + alpha * grad.sign()\n",
    "\n",
    "        x_adv = torch.max(torch.min(x_adv, x+epsilon), x-epsilon) # clip new x_adv back to [x-epsilon, x+epsilon]\n",
    "    return x_adv\n",
    "\n",
    "def mifgsm(model, x, y, loss_fn, epsilon=epsilon, num_iter=20, decay=1.0):\n",
    "    if num_iter < 1:\n",
    "        raise RuntimeError(f\"num_iter, {num_iter}, needs to be greater than 0!\") \n",
    "    alpha = epsilon / num_iter\n",
    "    x_adv = x\n",
    "    # initialze momentum tensor\n",
    "    momentum = torch.zeros_like(x).detach().to(device)\n",
    "    # write a loop of num_iter to represent the iterative times\n",
    "    for i in range(num_iter):\n",
    "        x_adv = x_adv.detach().clone()\n",
    "        x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
    "        loss = loss_fn(model(x_adv), y) # calculate loss\n",
    "        loss.backward() # calculate gradient\n",
    "        # TODO: Momentum calculation\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        grad = x_adv.grad.detach()\n",
    "        momentum = decay * momentum + grad / torch.norm(grad, p=1)\n",
    "        # x_adv = x_adv + alpha * grad.sign()\n",
    "        x_adv = x_adv + alpha * momentum.sign()\n",
    "        x_adv = torch.max(torch.min(x_adv, x+epsilon), x-epsilon) # clip new x_adv back to [x-epsilon, x+epsilon]\n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYCEQwmcrmH6"
   },
   "source": [
    "## Utils -- Attack\n",
    "* Recall\n",
    "  * ToTensor() can be seen as a function where $T(x) = x/255$.\n",
    "  * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
    "\n",
    "* Inverse function\n",
    "  * Inverse Normalize() can be seen as a function where $N^{-1}(x) = x*std+mean$ where $mean$ and $std$ are constants.\n",
    "  * Inverse ToTensor() can be seen as a function where $T^{-1}(x) = x*255$.\n",
    "\n",
    "* Special Noted\n",
    "  * ToTensor() will also convert the image from shape (height, width, channel) to shape (channel, height, width), so we also need to transpose the shape back to original shape.\n",
    "  * Since our dataloader samples a batch of data, what we need here is to transpose **(batch_size, channel, height, width)** back to **(batch_size, height, width, channel)** using np.transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5X_9x-7ro_w"
   },
   "outputs": [],
   "source": [
    "# perform adversarial attack and generate adversarial examples\n",
    "def gen_adv_examples(model, loader, attack, loss_fn):\n",
    "    model.eval()\n",
    "    adv_names = []\n",
    "    train_acc, train_loss = 0.0, 0.0\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_adv = attack(model, x, y, loss_fn) # obtain adversarial examples\n",
    "        yp = model(x_adv)\n",
    "        loss = loss_fn(yp, y)\n",
    "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
    "        train_loss += loss.item() * x.shape[0]\n",
    "        # store adversarial examples\n",
    "        adv_ex = ((x_adv) * std + mean).clamp(0, 1) # to 0-1 scale\n",
    "        adv_ex = (adv_ex * 255).clamp(0, 255) # 0-255 scale\n",
    "        adv_ex = adv_ex.detach().cpu().data.numpy().round() # round to remove decimal part\n",
    "        adv_ex = adv_ex.transpose((0, 2, 3, 1)) # transpose (bs, C, H, W) back to (bs, H, W, C)\n",
    "        '''\n",
    "        If it's not the first iteration, np.r_ is used to concatenate the new adversarial \n",
    "        examples (adv_ex) with the existing ones (adv_examples) along the first axis (bs). \n",
    "        This results in adv_examples containing all the adversarial examples generated so far.\n",
    "        '''\n",
    "        adv_examples = adv_ex if i == 0 else np.r_[adv_examples, adv_ex]\n",
    "    return adv_examples, train_acc / len(loader.dataset), train_loss / len(loader.dataset)\n",
    "\n",
    "# create directory which stores adversarial examples\n",
    "def create_dir(data_dir, adv_dir, adv_examples, adv_names):\n",
    "    if os.path.exists(adv_dir) is not True:  # Check if the adversarial directory already exists\n",
    "        shutil.rmtree(adv_dir)\n",
    "        _ = shutil.copytree(data_dir, adv_dir)  # Create a new directory by copying the original data (benign copies) directory\n",
    "\n",
    "    for example, name in zip(adv_examples, adv_names):\n",
    "        im = Image.fromarray(example.astype(np.uint8))  # Convert the example array to an image with unsigned integer pixel values\n",
    "        im.save(os.path.join(adv_dir, name))  # Save the image in the adversarial directory with the given name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_pMkmPytX3k"
   },
   "source": [
    "## Model / Loss Function\n",
    "\n",
    "Model list is available [here](https://github.com/osmr/imgclsmob/blob/master/pytorch/pytorchcv/model_provider.py). Please select models which has _cifar10 suffix. Some of the models cannot be accessed/loaded. You can safely skip them since TA's model will not use those kinds of models.\n",
    "\n",
    "Here's a list and they each might have different variances:\n",
    "```\n",
    "densenet\n",
    "diapreresnet\n",
    "diaresnet\n",
    "fractalnet\n",
    "msdnet\n",
    "nin\n",
    "preresnet\n",
    "pyramidnet\n",
    "resdropresnet\n",
    "resnet\n",
    "resnext\n",
    "rir\n",
    "ror3\n",
    "sepreresnet\n",
    "seresnet\n",
    "shakedropresnet\n",
    "shakeshakeresnet\n",
    "wrn\n",
    "xdensenet\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_list(model_list_file:str)->List[str]:\n",
    "    model_list = []\n",
    "    with open(model_list_file, 'r') as f:\n",
    "        model_name = f.readline().strip()\n",
    "        while len(model_name)>0:\n",
    "            model_list.append(model_name)\n",
    "            model_name = f.readline().strip()\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose effective models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and inference for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwto8xbPtYzQ",
    "outputId": "757c344a-be19-4192-ae2b-9ebdcd0b5e33"
   },
   "outputs": [],
   "source": [
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "import time\n",
    "\n",
    "tic0 = time.time()\n",
    "model_list = get_model_list('cifar10_models.lst')\n",
    "models = []\n",
    "print(f\"Loading all {len(model_list)} models.\")\n",
    "tic = time.time()\n",
    "for model_name in model_list:\n",
    "    model = ptcv_get_model(model_name, pretrained=True).to(device)\n",
    "    models.append(model)\n",
    "toc = time.time()\n",
    "print(f\"Total time for model loading: {toc-tic:.2f} seconds.\")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model_test_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwto8xbPtYzQ",
    "outputId": "757c344a-be19-4192-ae2b-9ebdcd0b5e33"
   },
   "outputs": [],
   "source": [
    "print(f\"Inference for each model\")\n",
    "for model, model_name in zip(models, model_list):\n",
    "    tic = time.time()\n",
    "    model_test_result[f'{model_name}'] = list(epoch_benign(model, adv_loader, loss_fn)) + [model_name]\n",
    "    toc = time.time()\n",
    "    print(f\"Time consumed: {toc-tic:.2f} seconds, for inference by model: {model_name}\")\n",
    "\n",
    "toc0 = time.time()\n",
    "print(f\"Total time consumed: {toc0-tic0:.1f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final chosen models: `chosen_model_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_model_test_result = sorted(model_test_result.items(), key=lambda x: x[1][1], reverse=False)\n",
    "sorted_model_test_result = [{k: v} for k, v in sorted_model_test_result]\n",
    "print(sorted_model_test_result)\n",
    "NUM_CHOSEN_MODELS = len(sorted_model_test_result) // 4 # len(sorted_model_test_result)\n",
    "chosen_model_names = [next(iter(c.keys())) for c in sorted_model_test_result[:NUM_CHOSEN_MODELS]]\n",
    "print(chosen_model_names)\n",
    "chosen_model_list = [ptcv_get_model(m, pretrained=True).to(device) for m in chosen_model_names]\n",
    "print([type(m) for m in chosen_model_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uslb7GPchtMI"
   },
   "source": [
    "## FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQwPTVUIhuTS",
    "outputId": "0cc23ace-b799-4025-9883-af7d04c545b1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fgsm_result = {}\n",
    "for model, model_name in zip(chosen_model_list, chosen_model_names):\n",
    "    adv_examples, fgsm_acc, fgsm_loss = gen_adv_examples(model, adv_loader, fgsm, loss_fn)\n",
    "    print(f'fgsm_acc = {fgsm_acc:.2%}, fgsm_loss = {fgsm_loss:.5f} for model: {model_name}')\n",
    "    fgsm_result[model] = [fgsm_acc, fgsm_loss, model_name]\n",
    "\n",
    "sorted_fgsm_result = sorted(fgsm_result.items(), key=lambda x: x[1][0], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([{m[1][-1]:m[1][:-1]} for m in sorted_fgsm_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQwPTVUIhuTS",
    "outputId": "0cc23ace-b799-4025-9883-af7d04c545b1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = sorted_fgsm_result[0][0]\n",
    "model_name = sorted_fgsm_result[0][1][-1]\n",
    "adv_examples, fgsm_acc, fgsm_loss = gen_adv_examples(model, adv_loader, fgsm, loss_fn)\n",
    "print(f'fgsm_acc = {fgsm_acc:.2%}, fgsm_loss = {fgsm_loss:.5f}, model = {model_name} ({type(model)})')\n",
    "\n",
    "create_dir(root, 'fgsm', adv_examples, adv_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXw6p0A6shZm"
   },
   "source": [
    "## I-FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQwPTVUIhuTS",
    "outputId": "0cc23ace-b799-4025-9883-af7d04c545b1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ifgsm_result = {}\n",
    "for model, model_name in zip(chosen_model_list, chosen_model_names):\n",
    "    tic = time.time()\n",
    "    adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(model, adv_loader, ifgsm, loss_fn)\n",
    "    toc = time.time()\n",
    "    print(f'Time consumed: {toc-tic:.1f} seconds, ifgsm_acc = {ifgsm_acc:.2%}, ifgsm_loss = {ifgsm_loss:.5f} for model: {model_name}')\n",
    "    ifgsm_result[model] = [ifgsm_acc, ifgsm_loss, model_name]\n",
    "\n",
    "sorted_ifgsm_result = sorted(ifgsm_result.items(), key=lambda x: x[1][0], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([{m[1][-1]:m[1][:-1]} for m in sorted_ifgsm_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQwPTVUIhuTS",
    "outputId": "0cc23ace-b799-4025-9883-af7d04c545b1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = sorted_ifgsm_result[0][0]\n",
    "model_name = sorted_ifgsm_result[0][1][-1]\n",
    "adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(model, adv_loader, ifgsm, loss_fn)\n",
    "print(f'ifgsm_acc = {ifgsm_acc:.2%}, ifgsm_loss = {ifgsm_loss:.5f}, model = {model_name} ({type(model)})')\n",
    "\n",
    "create_dir(root, 'ifgsm', adv_examples, adv_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXw6p0A6shZm"
   },
   "source": [
    "## MI-FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQwPTVUIhuTS",
    "outputId": "0cc23ace-b799-4025-9883-af7d04c545b1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mifgsm_result = {}\n",
    "for model, model_name in zip(chosen_model_list, chosen_model_names):\n",
    "    tic = time.time()\n",
    "    adv_examples, mifgsm_acc, mifgsm_loss = gen_adv_examples(model, adv_loader, mifgsm, loss_fn) # Use mifgsm as the algorithm\n",
    "    toc = time.time()\n",
    "    print(f'Time consumed: {toc-tic:.1f} seconds, mifgsm_acc = {mifgsm_acc:.2%}, mifgsm_loss = {mifgsm_loss:.5f} for model: {model_name}')\n",
    "    mifgsm_result[model] = [mifgsm_acc, mifgsm_loss, model_name]\n",
    "\n",
    "sorted_mifgsm_result = sorted(mifgsm_result.items(), key=lambda x: x[1][0], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([{m[1][-1]:m[1][:-1]} for m in sorted_mifgsm_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQwPTVUIhuTS",
    "outputId": "0cc23ace-b799-4025-9883-af7d04c545b1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = sorted_mifgsm_result[0][0]\n",
    "model_name = sorted_mifgsm_result[0][1][-1]\n",
    "adv_examples, mifgsm_acc, mifgsm_loss = gen_adv_examples(model, adv_loader, mifgsm, loss_fn)\n",
    "print(f'mifgsm_acc = {mifgsm_acc:.2%}, mifgsm_loss = {mifgsm_loss:.5f}, model = {model_name} ({type(model)})')\n",
    "\n",
    "create_dir(root, 'mifgsm', adv_examples, adv_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLZLbebigCA2"
   },
   "source": [
    "## Example of Ensemble Attack\n",
    "* Ensemble multiple models as your proxy model to increase the black-box transferability ([paper](https://arxiv.org/abs/1611.02770))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJcKiQNUgnPQ"
   },
   "outputs": [],
   "source": [
    "class ensembleNet(nn.Module):\n",
    "    def __init__(self, chosen_model_list:List[nn.Module]):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList(chosen_model_list)\n",
    "        self.softmax = nn.Softmax(dim=1) # .to(device)\n",
    "    def forward(self, x):\n",
    "        ensemble_logits = torch.zeros_like(self.models[0](x)).detach() # .to(device)\n",
    "        for i, m in enumerate(self.models):\n",
    "            # import ipdb; ipdb.set_trace()\n",
    "            ensemble_logits = ensemble_logits + m(x)\n",
    "        # TODO: sum up logits from multiple models\n",
    "        return self.softmax(ensemble_logits / len(self.models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjfJwJKeeaR2"
   },
   "source": [
    "* Construct your ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chosen = 5\n",
    "chosen_model_list = [m[0] for m in sorted_ifgsm_result[:num_chosen]]\n",
    "chosen_model_names = [m[1][-1] for m in sorted_ifgsm_result[:num_chosen]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stYFytogeIzI"
   },
   "outputs": [],
   "source": [
    "ensemble_model = ensembleNet(chosen_model_list).to(device)\n",
    "x = next(iter(adv_loader))[0][0].unsqueeze(0).to(device)\n",
    "ensemble_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUEsT06Iskt2",
    "outputId": "351a506f-2762-48c9-cad8-9ad54d231a38"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "adv_examples, ensemble_ifgsm_acc, ensemble_ifgsm_loss = gen_adv_examples(ensemble_model, adv_loader, ifgsm, loss_fn)\n",
    "print(f'ensemble_ifgsm_acc = {ensemble_ifgsm_acc:.2%}, ensemble_ifgsm_loss = {ensemble_ifgsm_loss:.5f}')\n",
    "\n",
    "create_dir(root, 'ensemble_ifgsm', adv_examples, adv_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQ-nYkkYexEE"
   },
   "source": [
    "## Compress the images\n",
    "* Submit the .tgz file to [JudgeBoi](https://ml.ee.ntu.edu.tw/hw10/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ItRo_S0M264N"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd fgsm\n",
    "!tar zcvf ../fgsm.tgz *\n",
    "%cd ..\n",
    "\n",
    "%cd ifgsm\n",
    "!tar zcvf ../ifgsm.tgz *\n",
    "%cd ..\n",
    "\n",
    "\n",
    "%cd mifgsm\n",
    "!tar zcvf ../mifgsm.tgz *\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FM_S886kFd8"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "id": "2FCuE2njkH1O",
    "outputId": "01c91960-eeec-4d0e-db2a-69e302c426c6"
   },
   "outputs": [],
   "source": [
    "random_model_idx = torch.randint(low=len(chosen_model_list), high=len(model_list), size=[1]).item()\n",
    "random_model_name = model_list[random_model_idx]\n",
    "random_model = ptcv_get_model(random_model_name, pretrained=True).to(device)\n",
    "print(f\"We randomly picked model: {random_model_name} (seq = {random_model_idx:d})\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "attack_name = 'ifgsm' # 'ensemble_ifgsm'\n",
    "chosen_pic_num = torch.randint(low=1, high=20, size=[1]).item()\n",
    "# chosen_pic_num = 2\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "cnt = 0\n",
    "for i, cls_name in enumerate(classes):\n",
    "    path = f'{cls_name}/{cls_name}{chosen_pic_num}.png'\n",
    "    # benign image\n",
    "    cnt += 1\n",
    "    plt.subplot(len(classes), 4, cnt)\n",
    "    im = Image.open(f'./data/{path}')\n",
    "    logit = random_model(transform(im).unsqueeze(0).to(device))[0]\n",
    "    predict = logit.argmax(-1).item()\n",
    "    prob = logit.softmax(-1)[predict].item()\n",
    "    plt.title(f'benign: {cls_name}{chosen_pic_num}.png\\n{classes[predict]}: {prob:.2%}')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(im))\n",
    "    # adversarial image\n",
    "    cnt += 1\n",
    "    plt.subplot(len(classes), 4, cnt)\n",
    "    im = Image.open(f'./{attack_name}/{path}')\n",
    "    logit = random_model(transform(im).unsqueeze(0).to(device))[0]\n",
    "    predict = logit.argmax(-1).item()\n",
    "    prob = logit.softmax(-1)[predict].item()\n",
    "    plt.title(f'adversarial: {cls_name}{chosen_pic_num}.png\\n{classes[predict]}: {prob:.2%}')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(im))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {
    "0f0ae0ae-1c33-4e44-af05-deac86e69359.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "id": "FUmKa02Vmp29"
   },
   "source": [
    "## Report Question\n",
    "* Make sure you follow below setup: the source model is \"resnet110_cifar10\", applying the vanilla fgsm attack on `dog2.png`. You can find the perturbed image in `fgsm/dog2.png`.\n",
    "\n",
    "![image.png](attachment:0f0ae0ae-1c33-4e44-af05-deac86e69359.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "8NW8ntCKY3VY",
    "outputId": "66db22c7-a1f8-4430-898d-8f33aa5e22a4"
   },
   "outputs": [],
   "source": [
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "cifar_10_mean = (0.491, 0.482, 0.447) # mean for the three channels of cifar_10 images\n",
    "cifar_10_std = (0.202, 0.199, 0.201) # std for the three channels of cifar_10 images\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(cifar_10_mean, cifar_10_std)  # Normalize the image using predefined means and standard deviations\n",
    "])\n",
    "\n",
    "\n",
    "model_name = \"resnet110_cifar10\"\n",
    "model = ptcv_get_model(model_name, pretrained=True).to(device)\n",
    "\n",
    "# original image\n",
    "path = f'dog/dog2.png' # f'airplane/airplane2.png'\n",
    "im = Image.open(f'./data/{path}')\n",
    "logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
    "predict = logit.argmax(-1).item()\n",
    "prob = logit.softmax(-1)[predict].item()\n",
    "plt.title(f'benign: {path}\\n{classes[predict]}: {prob:.2%}')\n",
    "plt.axis('off')\n",
    "plt.imshow(np.array(im))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# adversarial image \n",
    "attack_name = 'ensemble_ifgsm'\n",
    "im = Image.open(f'./{attack_name}/{path}')\n",
    "logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
    "predict = logit.argmax(-1).item()\n",
    "prob = logit.softmax(-1)[predict].item()\n",
    "plt.title(f'adversarial: {path}\\n{classes[predict]}: {prob:.2%}')\n",
    "plt.axis('off')\n",
    "plt.imshow(np.array(im))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AQkofrTnePa"
   },
   "source": [
    "## Passive Defense - JPEG compression\n",
    "JPEG compression by imgaug package, compression rate set to 70\n",
    "\n",
    "Reference: https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.JpegCompression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKuQaPp2mz7C"
   },
   "outputs": [],
   "source": [
    "# import imgaug.augmenters as iaa\n",
    "\n",
    "# # pre-process image\n",
    "# x = transforms.ToTensor()(im)*255\n",
    "# x = x.permute(1, 2, 0).numpy()\n",
    "# compressed_x = x.astype(np.uint8)\n",
    "\n",
    "# # TODO: use \"imgaug\" package to perform JPEG compression (compression rate = 70)\n",
    "# # compressed_x = ...\n",
    "\n",
    "# logit = model(transform(compressed_x).unsqueeze(0).to(device))[0]\n",
    "# predict = logit.argmax(-1).item()\n",
    "# prob = logit.softmax(-1)[predict].item()\n",
    "# plt.title(f'JPEG adversarial: dog2.png\\n{classes[predict]}: {prob:.2%}')\n",
    "# plt.axis('off')\n",
    "\n",
    "\n",
    "# plt.imshow(compressed_x)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML2022_hw10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Lhy Courses",
   "language": "python",
   "name": "lhy_courses"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
